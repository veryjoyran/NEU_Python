# 二手房数据爬取与展示系统 - 客户端-服务器 (Client-Server) 版本

## 项目简介
本项目是一个基于客户端-服务器架构的二手房数据爬取与展示系统。服务器端使用 Flask 提供 RESTful API，负责数据的爬取、存储和统计分析；客户端使用 Tkinter 构建图形用户界面，允许用户输入城市代码进行数据爬取、查看存储的数据以及展示统计图表。系统还包括自动化测试用例和定时数据更新功能，确保数据的实时性和系统的可靠性。

---

## 功能概述
- **数据爬取**：用户在客户端输入城市首字母，服务器端将自动爬取对应城市的二手房数据。
- **数据存储**：爬取的数据会自动保存到服务器端的 SQLite 数据库中。
- **数据展示**：客户端通过图形界面查看存储在数据库中的房源数据。
- **统计分析**：生成二手房数量的柱状图，直观展示不同房型的分布情况。
- **自动更新**：服务器端设置定时任务，每周自动爬取并更新新房源数据。
- **自动化测试**：包含对服务器 API 的自动化测试用例，确保各项功能正常运行。
- **日志记录**：服务器端记录关键操作和错误日志，便于监控和调试。

---

## 环境要求
### 通用
- **Python 3.7+**

### 服务器端依赖
- Flask
- Flask-RESTful
- Flask-CORS
- SQLAlchemy
- apscheduler
- requests
- beautifulsoup4
- lxml

### 客户端依赖
- requests
- matplotlib
- tkinter

---

## 项目结构
Project3/     
├── client/     
│   ├── main.py    
│   └── requirements.txt    
├── server/     
│   ├── app.py    
│   ├── scraper.py    
│   ├── database.py    
│   ├── scheduler.py    
│   ├── tests/    
│   │   └── test_api.py    
│   └── requirements.txt    
└── README.md    


---

## 使用方法

### 1. 设置服务器端
#### a. 准备环境
1. 进入 `server` 文件夹：
    ```bash
    cd Project3/server
    ```
2. 创建并激活虚拟环境（可选但推荐）：
    ```bash
    python -m venv venv
    source venv/bin/activate  # 对于Windows使用 `venv\Scripts\activate`
    ```
3. 安装依赖：
    ```bash
    pip install -r requirements.txt
    ```

#### b. 启动服务器
在 `server` 文件夹中运行：
```bash
python app.py
```
服务器将运行在 http://localhost:5000。

### 2。运行客户端
#### a. 准备环境
1. 打开一个新的终端，进入 client 文件夹：
    ```bash
    cd Project3/client
    ```
2. 创建并激活虚拟环境（可选但推荐）：

3.    
   ```bash
    pip install -r requirements.txt
   ```
#### b. 启动客户端
在 client 文件夹中运行：
```bash
python main.py
```

### 3. 操作说明
#### a. 输入城市代码
在客户端界面中输入城市的首字母（例如 bj、sh、sy、hf）。

#### b. 输入爬取页数
输入要爬取的页数（默认为5页）。

#### c. 开始爬取
点击“开始爬取”按钮，系统将向服务器发送请求，服务器将爬取指定城市的二手房数据并自动保存到数据库中。爬取完成后，客户端会弹出提示消息，告知新增的记录数，并在表格中显示爬取到的数据。

#### d. 显示数据
点击“显示数据”按钮，客户端将从服务器获取并展示数据库中的所有房源数据。

#### e. 显示统计图
点击“显示统计图”按钮，客户端将从服务器获取统计数据并生成包含数量标签的柱状图，直观展示不同房型的分布情况。


### 4. 注意事项
数据库文件：所有爬取的房源数据将保存在 houses.db 中，位于服务器端根目录。数据库文件在第一次运行时自动创建。
城市输入格式：城市的首字母应为英文字符（如 bj、sh、sy、hf）。
爬取时间：根据网络情况和城市数据的不同，爬取过程可能需要一定时间，请耐心等待。默认爬取5页数据，如需更多，可在客户端输入框中调整爬取页数。


## 自动化测试
### 1.运行测试用例
确保服务器正在运行，然后在 server/tests 目录下运行测试：
```bash
cd Project3/server/tests
python test_api.py

```
### 2. 测试用例说明
测试用例涵盖以下功能：

数据爬取：测试 /api/scrape 端点是否能够正确爬取并保存数据。
获取房源数据：测试 /api/houses 端点是否能够正确返回所有房源数据。
统计分析：测试 /api/statistics 端点是否能够正确返回统计数据。

## 自动更新
服务器端配置了定时任务，每周自动爬取并更新新房源数据。确保服务器持续运行以执行定时任务。
### 定时任务配置
自动更新功能由 APScheduler 实现，具体配置在 scheduler.py 中。默认每周执行一次爬取任务，爬取新增的房源数据并保存到数据库中。

## 日志记录
服务器端通过 Python 的 logging 模块记录关键操作和错误日志，便于监控和调试。    
日志输出至控制台，包含爬取进度、保存数据情况及错误信息。